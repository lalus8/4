{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "teBtFrQFd5b8",
        "outputId": "7db4da18-6eff-4de7-a03a-972952dbd443"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ef9995a793fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from scipy.special import softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFw13pSYd5cM"
      },
      "source": [
        "tweet = \"@Aryaman today's cold @ home ðŸ˜‰â€™ http://sentiment4.ml/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxzKXkp9d5cb"
      },
      "outputs": [],
      "source": [
        "tweet = 'Great project! follow me ðŸ˜‰'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zpAQ-xZd5cb"
      },
      "source": [
        "precprcess tweet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfKU7WTNd5cb"
      },
      "outputs": [],
      "source": [
        "tweet_words = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4apF2tad5cb"
      },
      "outputs": [],
      "source": [
        "for word in tweet.split(' '):\n",
        "    if word.startswith('@') and len(word) > 1:\n",
        "        word = '@user'\n",
        "    \n",
        "    elif word.startswith('http'):\n",
        "        word = \"http\"\n",
        "    tweet_words.append(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgyZv-VMd5cb"
      },
      "outputs": [],
      "source": [
        "tweet_proc = \" \".join(tweet_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0H3NfH_d5cb"
      },
      "source": [
        "load model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxX3-lHQd5cb"
      },
      "outputs": [],
      "source": [
        "roberta = \"cardiffnlp/twitter-roberta-base-sentiment\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRteXAL6d5cr"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(roberta)\n",
        "tokenizer = AutoTokenizer.from_pretrained(roberta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tnd9hHSAd5cr"
      },
      "outputs": [],
      "source": [
        "labels = ['Negative', 'Neutral', 'Positive']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zozvYGbDd5cr"
      },
      "source": [
        "sentiment analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7sVyNAsd5cr"
      },
      "outputs": [],
      "source": [
        "encoded_tweet = tokenizer(tweet_proc, return_tensors='pt')\n",
        "# output = model(encoded_tweet['input_ids'], encoded_tweet['attention_mask'])\n",
        "output = model(**encoded_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_np1s5rid5cr"
      },
      "outputs": [],
      "source": [
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "tw-sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}